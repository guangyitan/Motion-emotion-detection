{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to implement\n",
    "# Webcam Motion Detector\n",
    "\n",
    "# importing OpenCV, time and Pandas library\n",
    "import cv2, time, pandas, os\n",
    "# importing datetime class from datetime library\n",
    "from datetime import datetime\n",
    "\n",
    "# Assigning our static_back to None\n",
    "static_back = None\n",
    "\n",
    "# List when any moving object appear\n",
    "motion_list = [ None, None ]\n",
    "\n",
    "# Time of movement\n",
    "time = []\n",
    "\n",
    "# Initializing DataFrame, one column is start\n",
    "# time and other column is end time\n",
    "df = pandas.DataFrame(columns = [\"Start\", \"End\"])\n",
    "\n",
    "# Capturing video\n",
    "# video = cv2.VideoCapture(0)\n",
    "video = cv2.VideoCapture(os.getcwd() + \"/data/vid2_part1.mp4\")\n",
    "\n",
    "\n",
    "# Infinite while loop to treat stack of image as video\n",
    "while True:\n",
    "\t# Reading frame(image) from video\n",
    "\tcheck, frame = video.read()\n",
    "\n",
    "\t# Initializing motion = 0(no motion)\n",
    "\tmotion = 0\n",
    "\n",
    "\t# Converting color image to gray_scale image\n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t# Converting gray scale image to GaussianBlur\n",
    "\t# so that change can be find easily\n",
    "\tgray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "\t# In first iteration we assign the value\n",
    "\t# of static_back to our first frame\n",
    "\tif static_back is None:\n",
    "\t\tstatic_back = gray\n",
    "\t\tcontinue\n",
    "\n",
    "\t# Difference between static background\n",
    "\t# and current frame(which is GaussianBlur)\n",
    "\tdiff_frame = cv2.absdiff(static_back, gray)\n",
    "\n",
    "\t# If change in between static background and\n",
    "\t# current frame is greater than 30 it will show white color(255)\n",
    "\tthresh_frame = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "\tthresh_frame = cv2.dilate(thresh_frame, None, iterations = 2)\n",
    "\n",
    "\t# Finding contour of moving object\n",
    "\tcnts,_ = cv2.findContours(thresh_frame.copy(),\n",
    "\t\t\t\t\tcv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\tfor contour in cnts:\n",
    "\t\tif cv2.contourArea(contour) < 10000:\n",
    "\t\t\tcontinue\n",
    "\t\tmotion = 1\n",
    "\n",
    "\t\t(x, y, w, h) = cv2.boundingRect(contour)\n",
    "\t\t# making green rectangle around the moving object\n",
    "\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "\t# Appending status of motion\n",
    "\tmotion_list.append(motion)\n",
    "\n",
    "\tmotion_list = motion_list[-2:]\n",
    "\n",
    "\t# Appending Start time of motion\n",
    "\tif motion_list[-1] == 1 and motion_list[-2] == 0:\n",
    "\t\ttime.append(datetime.now())\n",
    "\n",
    "\t# Appending End time of motion\n",
    "\tif motion_list[-1] == 0 and motion_list[-2] == 1:\n",
    "\t\ttime.append(datetime.now())\n",
    "\n",
    "\t# Displaying image in gray_scale\n",
    "\tcv2.imshow(\"Gray Frame\", gray)\n",
    "\n",
    "\t# Displaying the difference in currentframe to\n",
    "\t# the staticframe(very first_frame)\n",
    "\tcv2.imshow(\"Difference Frame\", diff_frame)\n",
    "\n",
    "\t# Displaying the black and white image in which if\n",
    "\t# intensity difference greater than 30 it will appear white\n",
    "\tcv2.imshow(\"Threshold Frame\", thresh_frame)\n",
    "\n",
    "\t# Displaying color frame with contour of motion of object\n",
    "\tcv2.imshow(\"Color Frame\", frame)\n",
    "\n",
    "\tkey = cv2.waitKey(1)\n",
    "\t# if q entered whole process will stop\n",
    "\tif key == ord('q'):\n",
    "\t\t# if something is movingthen it append the end time of movement\n",
    "\t\tif motion == 1:\n",
    "\t\t\ttime.append(datetime.now())\n",
    "\t\tbreak\n",
    "\n",
    "# Appending time of motion in DataFrame\n",
    "# for i in range(0, len(time), 2):\n",
    "# \tdf = df.append({\"Start\":time[i], \"End\":time[i + 1]}, ignore_index = True)\n",
    "\n",
    "# Creating a CSV file in which time of movements will be saved\n",
    "# df.to_csv(\"Time_of_movements.csv\")\n",
    "\n",
    "video.release()\n",
    "\n",
    "# Destroying all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you watch previous tutorials you will understand what is happening behind syntax\n",
    "briefly, \n",
    "first step, movement is difference between two frames \n",
    "second, difference has noises because of details and light on video so gaussian blurring is eliminating the noises,\n",
    "third, obtaining threshold from clean difference\n",
    "fourth, dilating for eliminating district small weak threshold lines which corrupt healthy threshold detection\n",
    "fifth, finding contours from clean threshold\n",
    "sixth, eliminating small contours which can not be a human by filtering contour area\n",
    "seventh, drawing rectangles for each detected contour on the frame, rectangle dimensions obtained from cv2.boundingRect(contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap = cv2.VideoCapture('vtest.avi')\n",
    "cap = cv2.VideoCapture(os.getcwd() + \"/data/clip2_7s.mp4\")\n",
    "\n",
    "# cap = cv2.VideoCapture(os.getcwd() + \"/data/vid2_part1.mp4\")\n",
    "\n",
    "# frame_width = int( cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# frame_height =int( cap.get( cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "\n",
    "# out = cv2.VideoWriter(\"output.avi\", fourcc, 5.0, (1280,720))\n",
    "\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "print(frame1.shape)\n",
    "while cap.isOpened():\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 50, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contour) < 600:\n",
    "            continue\n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1, (0, 0, 255), 3)\n",
    "    #cv2.drawContours(frame1, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # image = cv2.resize(frame1, (1280,720))\n",
    "    # out.write(image)\n",
    "    cv2.imshow(\"feed\", frame1)\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    if cv2.waitKey(40) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "# out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('deepFacepy37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21b6fde438783047a9b28b66d2ac1a8262ef604e581950bf28e988f9a8bd21db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
